# Compliance Strategy Development

## Learning Objectives

By the end of this chapter, you will be able to:
- Design a comprehensive AI Act compliance strategy aligned with regulatory deadlines
- Structure governance frameworks appropriate to organisational complexity
- Develop resource allocation plans with realistic budgeting considerations
- Create metrics and KPIs to track compliance program effectiveness
- Build stakeholder engagement strategies for organisation-wide adoption

---

## Introduction: The Strategic Imperative

Compliance with the AI Act is not merely a legal requirementâ€”it is a strategic opportunity to build trust, demonstrate responsible AI practices, and create competitive advantage. Organisations that approach compliance reactively will struggle; those with proactive, strategic programs will thrive.

> **Expert Insight:** The most successful compliance programs I've observed treat the AI Act not as a burden but as a framework for operational excellence. When done right, compliance drives better AI systems, not just compliant ones.

The AI Act's phased implementation timeline (Article 113) provides a structured runway for compliance, but organisations must begin now to meet each milestone.

---

## Phase 1: Discovery and Assessment (Months 1-3)

### 1.1 AI System Inventory

The foundation of any compliance strategy is knowing what AI systems you have. This sounds simple but proves challenging for most organisations.

| Inventory Element | What to Capture | Why It Matters |
| --- | --- | --- |
| **System identification** | Name, version, vendor, internal ID | Trackability and accountability |
| **Purpose and function** | Business objective, how AI achieves it | Risk classification basis |
| **Deployment context** | Where, how, who uses it | Determines use case risk |
| **Data inputs** | Types, sources, personal data involvement | GDPR intersection, bias risk |
| **Decision outputs** | What decisions, who affected | Fundamental rights impact |
| **Autonomy level** | Fully automated vs. human-assisted | Human oversight requirements |
| **Lifecycle stage** | Development, testing, production, sunset | Applicable obligations |

**Discovery Methods:**

1. **Top-down**: Survey business units, review procurement records, audit IT systems
2. **Bottom-up**: Technical scanning for ML libraries, model files, API calls to AI services
3. **Hybrid**: Combine both approaches for completeness

> âš ï¸ **Warning:** Shadow AI is a significant risk. Employees may be using AI tools (ChatGPT, code assistants, image generators) without IT knowledge. Your inventory must capture these.

### 1.2 Risk Classification Mapping

Once inventoried, each system must be mapped to the AI Act's risk categories:

| Risk Level | Article Reference | Examples | Compliance Path |
| --- | --- | --- | --- |
| **Unacceptable** | Article 5 | Social scoring, subliminal manipulation | Immediate prohibition |
| **High-risk (Annex I)** | Annex I + Articles 6(2), 8-15 | Safety components of products | Full Chapter 2 requirements |
| **High-risk (Annex III)** | Annex III + Articles 6(1), 8-15 | HR, credit, law enforcement AI | Full Chapter 2 requirements |
| **Limited risk** | Article 50 | Chatbots, deepfakes, emotion detection | Transparency obligations |
| **Minimal risk** | Article 95 | Spam filters, games | Voluntary codes, no obligations |

**Classification Decision Framework:**

```
Step 1: Is the practice prohibited under Article 5?
        â†’ YES: Cease immediately
        â†’ NO: Continue to Step 2

Step 2: Is it a safety component of Annex I product?
        â†’ YES: High-risk (Annex I path)
        â†’ NO: Continue to Step 3

Step 3: Is the use case listed in Annex III?
        â†’ YES: Continue to Step 4
        â†’ NO: Continue to Step 5

Step 4: Does it pose significant risk of harm?
        â†’ YES: High-risk (Annex III)
        â†’ NO: Not high-risk (Article 6(3) exception)

Step 5: Does it require transparency (emotion recognition, deepfakes, chatbots)?
        â†’ YES: Limited risk
        â†’ NO: Minimal risk
```

### 1.3 Gap Analysis

Compare current state against requirements for each classified system:

| Requirement Area | Article | Assessment Questions | Gap Indicators |
| --- | --- | --- | --- |
| **Risk management** | Article 9 | Is there a documented RMS? Is it updated? | No formal system, outdated analysis |
| **Data governance** | Article 10 | Are training data practices documented? Bias tested? | No data documentation, no bias testing |
| **Technical documentation** | Article 11 | Does documentation meet Annex IV requirements? | Missing elements, not updated |
| **Record-keeping** | Article 12 | Are logs kept for appropriate duration? | No logging, insufficient retention |
| **Transparency** | Article 13 | Can users understand the AI's decisions? | No explanations, unclear instructions |
| **Human oversight** | Article 14 | Are oversight measures in place and effective? | No oversight, ineffective controls |
| **Accuracy/robustness** | Article 15 | Is performance validated? Cybersecurity adequate? | No validation, weak security |

**Prioritisation Matrix:**

| | High Regulatory Risk | Low Regulatory Risk |
| --- | --- | --- |
| **High Effort** | Priority 2: Plan carefully | Priority 4: Long-term |
| **Low Effort** | Priority 1: Quick wins | Priority 3: Opportunistic |

---

## Phase 2: Strategy Design (Months 3-6)

### 2.1 Governance Structure Design

Effective AI governance requires clear roles, responsibilities, and decision-making authority:

| Role | Responsibilities | Skills Required | Typical Location |
| --- | --- | --- | --- |
| **AI Compliance Officer** | Overall program ownership, regulatory liaison, reporting | Legal, regulatory, AI knowledge | Legal/Compliance |
| **AI Ethics Lead** | Ethical review, fundamental rights assessment | Ethics, philosophy, social science | Risk/Ethics team |
| **Technical AI Lead** | Technical documentation, validation, monitoring | ML engineering, software architecture | Engineering/IT |
| **Data Governance Lead** | Data quality, bias prevention, GDPR alignment | Data science, privacy law | Data team |
| **Business AI Sponsors** | Use case approval, risk acceptance, resource allocation | Business domain, risk management | Business units |

**Governance Bodies:**

1. **AI Governance Committee** (Strategic)
   - Composition: C-suite, legal, risk, technology leaders
   - Meeting frequency: Quarterly
   - Decisions: Policy approval, major risk acceptance, resource allocation

2. **AI Review Board** (Tactical)
   - Composition: Technical leads, compliance, ethics, business representatives
   - Meeting frequency: Monthly or per-project
   - Decisions: System classification, risk assessment approval, deployment authorisation

3. **AI Working Group** (Operational)
   - Composition: Practitioners, analysts, support staff
   - Meeting frequency: Weekly/bi-weekly
   - Activities: Implementation, monitoring, issue escalation

### 2.2 Policy Framework Development

A comprehensive policy framework covers multiple layers:

| Policy Type | Purpose | Key Contents |
| --- | --- | --- |
| **AI Strategy Policy** | Sets organisational direction for AI | Vision, principles, risk appetite, ethical commitments |
| **AI Development Policy** | Governs how AI is built | Development standards, testing requirements, documentation mandates |
| **AI Procurement Policy** | Controls AI purchasing | Vendor assessment, contractual requirements, compliance verification |
| **AI Deployment Policy** | Manages operational use | Approval processes, monitoring requirements, incident procedures |
| **AI Data Policy** | Ensures data quality and governance | Training data requirements, bias prevention, retention rules |

> **Expert Insight:** Policies without teeth are worthless. Each policy must have clear enforcement mechanisms, escalation paths, and consequences for non-compliance. I've seen too many beautiful policy documents gathering dust.

### 2.3 Conformity Assessment Preparation

For high-risk AI systems, conformity assessment is mandatory. Prepare for either path:

| Assessment Type | When Required | Preparation Needed |
| --- | --- | --- |
| **Internal control (Article 43(2))** | Most Annex III systems | Internal QMS certification, documentation readiness, competent assessors |
| **Third-party (Notified Body)** | Annex I products, biometric systems | Notified body selection, budget allocation, timeline planning |

**Documentation Checklist for Conformity Assessment:**

| Document | Annex IV Reference | Typical Length | Preparation Time |
| --- | --- | --- | --- |
| General description | IV(1)(a)-(e) | 10-20 pages | 2-4 weeks |
| Design specifications | IV(2)(a)-(g) | 30-100+ pages | 4-12 weeks |
| System architecture | IV(2)(b) | 20-50 pages | 2-6 weeks |
| Data governance | IV(2)(d) | 15-30 pages | 3-6 weeks |
| Risk management | IV(2)(c) | 20-40 pages | 4-8 weeks |
| Validation results | IV(2)(e) | 30-100+ pages | 6-12 weeks |
| Human oversight measures | IV(2)(f) | 10-20 pages | 2-4 weeks |
| Monitoring procedures | IV(2)(g) | 10-15 pages | 2-4 weeks |
| Instructions for use | IV(3) | 20-50 pages | 3-6 weeks |

---

## Phase 3: Implementation (Months 6-18)

### 3.1 Technical Implementation Roadmap

| Workstream | Activities | Dependencies | Typical Duration |
| --- | --- | --- | --- |
| **Logging infrastructure** | Implement Article 12 compliant logging | System architecture | 2-4 months |
| **Monitoring systems** | Deploy PMM capabilities | Logging infrastructure | 3-6 months |
| **Human oversight tools** | Build oversight interfaces | UX design, process definition | 3-6 months |
| **Documentation systems** | Create/update technical documentation | Subject matter input | 4-8 months |
| **Testing frameworks** | Establish validation and bias testing | Test data, methodology | 3-6 months |
| **Incident management** | Implement detection and response | Monitoring systems | 2-4 months |

### 3.2 Training and Awareness Program

Article 4 requires AI literacy for all staff involved with AI systems:

| Audience | Training Focus | Format | Frequency |
| --- | --- | --- | --- |
| **Board/Executives** | Strategic implications, liability, governance | Briefings, workshops | Annual + updates |
| **AI Practitioners** | Technical requirements, documentation, validation | Detailed training | Initial + annual |
| **Deployers/Users** | System-specific instructions, oversight duties | Hands-on training | Per-system + refresher |
| **Procurement** | Vendor assessment, contractual requirements | Process training | Initial + updates |
| **Legal/Compliance** | Regulatory requirements, enforcement, penalties | Deep-dive sessions | Initial + regulatory updates |
| **All Staff** | AI literacy, basic awareness, reporting | E-learning | Annual |

### 3.3 Vendor Management

For AI systems procured from third parties, establish a vendor compliance program:

| Activity | Purpose | Timing |
| --- | --- | --- |
| **Compliance questionnaire** | Assess vendor's AI Act readiness | During procurement |
| **Documentation review** | Verify Article 11/Annex IV compliance | Pre-contract |
| **Contractual provisions** | Ensure compliance obligations flow down | Contract drafting |
| **Ongoing monitoring** | Verify continued compliance | Quarterly/annually |
| **Incident coordination** | Align incident response procedures | Pre-deployment |

**Key Contractual Clauses:**

- Provider's compliance with all applicable AI Act obligations
- Right to audit technical documentation
- Notification of material changes affecting compliance
- Cooperation with conformity assessment
- Incident reporting and coordination obligations
- Indemnification for non-compliance

---

## Phase 4: Operational Excellence (Ongoing)

### 4.1 Continuous Monitoring Framework

| Monitoring Area | Metrics | Frequency | Threshold/Target |
| --- | --- | --- | --- |
| **System performance** | Accuracy, precision, recall, F1 | Continuous/daily | Within validated range |
| **Bias indicators** | Demographic parity, equalised odds | Weekly/monthly | No significant drift |
| **Incident metrics** | Incidents per system, resolution time | Weekly | Zero critical, <5 minor |
| **Compliance status** | Documentation currency, assessment validity | Monthly | 100% current |
| **Training completion** | Staff trained per role | Monthly | 100% completion |

### 4.2 Continuous Improvement Cycle

```
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚                                                     â”‚
   â”‚  PLAN: Identify improvement opportunities from      â”‚
   â”‚        monitoring data, audits, incidents           â”‚
   â”‚                    â”‚                                â”‚
   â”‚                    â–¼                                â”‚
   â”‚  DO: Implement improvements to systems,             â”‚
   â”‚      processes, documentation                       â”‚
   â”‚                    â”‚                                â”‚
   â”‚                    â–¼                                â”‚
   â”‚  CHECK: Validate improvements effective,            â”‚
   â”‚         no unintended consequences                  â”‚
   â”‚                    â”‚                                â”‚
   â”‚                    â–¼                                â”‚
   â”‚  ACT: Standardise successful improvements,          â”‚
   â”‚       update policies/procedures                    â”‚
   â”‚                    â”‚                                â”‚
   â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Regulatory Change Management

The AI Act will evolve through delegated acts, implementing acts, and guidance. Establish a process to track and respond:

| Change Type | Examples | Response Time | Typical Actions |
| --- | --- | --- | --- |
| **Delegated acts** | Annex III updates, high-risk additions | 6-12 months | Classification review, gap analysis |
| **Implementing acts** | Standardised documentation, DoC format | 3-6 months | Template updates, process adjustment |
| **Harmonised standards** | ISO/IEC standards adopted | 6-12 months | Technical alignment |
| **Commission guidance** | Implementation guidelines, FAQ | 1-3 months | Interpretation alignment |
| **Case law/decisions** | Enforcement actions, court rulings | As needed | Risk reassessment |

---

## Timeline and Milestone Planning

### Critical Deadlines (Article 113)

| Date | Milestone | Systems Affected | Key Actions |
| --- | --- | --- | --- |
| **2 February 2025** | Prohibited practices + AI literacy | All AI systems | Article 5 audit, training rollout |
| **2 August 2025** | GPAI compliance | GPAI models | Full Article 53-56 compliance |
| **2 August 2025** | Governance operational | N/A | Authorities designated, operational |
| **2 August 2026** | Full high-risk compliance | High-risk AI systems | Chapter 2 requirements fully met |
| **2 August 2027** | Annex I integration | Product safety AI | Full product regulation alignment |

### Sample Implementation Timeline

| Phase | Q1 2025 | Q2 2025 | Q3 2025 | Q4 2025 | Q1-Q2 2026 | Q3 2026 |
| --- | --- | --- | --- | --- | --- | --- |
| **Discovery** | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | | | | | |
| **Gap Analysis** | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | | | | |
| **Prohibited Practice Audit** | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | | | | | |
| **AI Literacy Training** | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | | | | | |
| **GPAI Compliance** | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | | | |
| **Governance Build** | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆ | | |
| **High-Risk Documentation** | | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆ |
| **Technical Controls** | | | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |
| **Conformity Assessment** | | | | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |
| **Operational Launch** | | | | | â–ˆâ–ˆâ–ˆ | â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ |

---

## Resource Planning and Budgeting

### Resource Categories

| Category | Typical Components | Rough Sizing Factors |
| --- | --- | --- |
| **Internal staff** | Compliance, legal, technical, business FTEs | 0.5-2 FTE per 10 high-risk systems |
| **External advisory** | Legal counsel, technical consultants, training providers | â‚¬50-200K initial, â‚¬20-50K ongoing/year |
| **Technology** | Monitoring tools, documentation systems, testing platforms | â‚¬25-100K initial, â‚¬10-30K ongoing/year |
| **Training** | Content development, delivery, platforms | â‚¬10-50K initial, â‚¬5-15K ongoing/year |
| **Conformity assessment** | Internal assessment effort, notified body fees | â‚¬10-50K per high-risk system |

### Budget Estimation Framework

| Organisation Size | High-Risk Systems | Estimated Year 1 Investment | Ongoing Annual |
| --- | --- | --- | --- |
| **SME** | 1-5 | â‚¬75K - â‚¬200K | â‚¬30K - â‚¬75K |
| **Mid-size** | 5-20 | â‚¬200K - â‚¬750K | â‚¬75K - â‚¬250K |
| **Large enterprise** | 20-100+ | â‚¬750K - â‚¬3M+ | â‚¬250K - â‚¬1M+ |

> **Expert Insight:** The biggest budget mistake I see is underestimating the ongoing costs. Compliance isn't a projectâ€”it's a permanent operational function. Plan for steady-state costs, not just implementation.

---

## Success Metrics and KPIs

### Compliance Program KPIs

| KPI | Definition | Target | Measurement Frequency |
| --- | --- | --- | --- |
| **Inventory completeness** | % of AI systems captured in inventory | 100% | Quarterly |
| **Classification accuracy** | % of systems correctly classified | 100% | After each review |
| **Documentation currency** | % of docs updated within last 12 months | 100% | Monthly |
| **Conformity status** | % of high-risk systems with valid conformity | 100% by Aug 2026 | Monthly |
| **AI literacy coverage** | % of relevant staff trained | 100% by Feb 2025 | Monthly |
| **Incident response time** | Average time from detection to initial response | < 4 hours | Per incident |
| **Corrective action closure** | % of CAPAs closed within target time | > 95% | Monthly |
| **Audit findings** | Major findings per audit | Zero | Per audit |

### Executive Dashboard Template

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AI ACT COMPLIANCE DASHBOARD - [Month Year]                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  OVERALL COMPLIANCE STATUS:  ğŸŸ¢ ON TRACK                    â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ SYSTEMS: 45    â”‚  â”‚ HIGH-RISK: 12  â”‚  â”‚ GPAI: 3       â”‚ â”‚
â”‚  â”‚ Inventoried    â”‚  â”‚ Compliant: 10  â”‚  â”‚ Compliant: 2  â”‚ â”‚
â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘   â”‚  â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘    â”‚ â”‚
â”‚  â”‚     100%       â”‚  â”‚     83%        â”‚  â”‚     67%       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                             â”‚
â”‚  DEADLINE READINESS:                                        â”‚
â”‚  Feb 2025 (Prohibited/Literacy): â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100%   â”‚
â”‚  Aug 2025 (GPAI):                â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘  85%   â”‚
â”‚  Aug 2026 (High-Risk):           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  50%   â”‚
â”‚                                                             â”‚
â”‚  ISSUES REQUIRING ATTENTION:                                â”‚
â”‚  âš ï¸ 2 high-risk systems pending documentation completion    â”‚
â”‚  âš ï¸ 1 GPAI model awaiting systemic risk assessment          â”‚
â”‚  âœ… AI literacy training completed ahead of schedule        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Stakeholder Engagement Strategy

### Stakeholder Mapping

| Stakeholder Group | Interest Level | Influence | Engagement Strategy |
| --- | --- | --- | --- |
| **Board/C-Suite** | High | High | Quarterly briefings, risk reporting, decision escalation |
| **Business Unit Heads** | Medium-High | High | Monthly updates, project sponsorship, resource approval |
| **IT/Engineering** | High | High | Close collaboration, technical design input, tool selection |
| **Legal/Compliance** | High | High | Joint ownership, regulatory interpretation, policy drafting |
| **Procurement** | Medium | Medium | Process integration, vendor requirements, contract support |
| **HR** | Medium | Medium | Training coordination, AI in HR compliance |
| **Finance** | Medium | Medium | Budget approval, cost tracking, penalty risk awareness |
| **Frontline Staff** | Medium | Low | Training, feedback channels, incident reporting |

### Communication Plan

| Audience | Content | Channel | Frequency |
| --- | --- | --- | --- |
| **Board** | Strategic status, major risks, decisions needed | Board pack, presentation | Quarterly |
| **Steering Committee** | Project status, issues, upcoming milestones | Meeting, dashboard | Monthly |
| **Project Team** | Detailed progress, blockers, tasks | Stand-ups, tracking tool | Weekly |
| **All Employees** | Awareness, policy updates, training | Intranet, email, town hall | As needed |
| **External (regulators)** | Compliance documentation, queries | Formal correspondence | As required |

---

## Compliance Strategy Checklist

### Phase 1: Discovery and Assessment
- [ ] Complete AI system inventory across all business units
- [ ] Verify inventory includes shadow AI and third-party tools
- [ ] Classify each system against AI Act risk categories
- [ ] Document classification rationale for each system
- [ ] Perform gap analysis against applicable requirements
- [ ] Prioritise remediation based on risk and deadline
- [ ] Present findings to executive sponsor

### Phase 2: Strategy Design
- [ ] Define governance structure and roles
- [ ] Establish AI Governance Committee
- [ ] Create AI Review Board with clear charter
- [ ] Develop policy framework (strategy, development, procurement, deployment, data)
- [ ] Design conformity assessment approach per system
- [ ] Create vendor management program
- [ ] Develop resource plan and budget
- [ ] Obtain executive approval for strategy

### Phase 3: Implementation
- [ ] Implement technical controls (logging, monitoring, oversight)
- [ ] Create/update all required documentation
- [ ] Build validation and testing frameworks
- [ ] Deploy incident management capabilities
- [ ] Roll out training program to all audiences
- [ ] Integrate AI requirements into procurement
- [ ] Conduct conformity assessments (internal or notified body)
- [ ] Affix CE marking and issue DoC for compliant systems

### Phase 4: Operational Excellence
- [ ] Activate continuous monitoring
- [ ] Establish regular compliance review cadence
- [ ] Implement regulatory change management
- [ ] Define and track KPIs
- [ ] Report to governance bodies per schedule
- [ ] Conduct periodic internal audits
- [ ] Continuously improve based on learnings

---

## Key Takeaways

- **Strategic approach** is essentialâ€”reactive compliance is expensive and risky
- **Inventory first**: You cannot manage what you do not know exists
- **Classification** determines obligationsâ€”get it right with documented rationale
- **Governance structure** must match organisational complexity with clear accountability
- **Phased implementation** aligned to AI Act deadlines (Feb 2025, Aug 2025, Aug 2026)
- **Documentation** is the backbone of complianceâ€”budget significant effort
- **Training** is a legal requirement (Article 4) and an enabler of compliance culture
- **Vendor management** is criticalâ€”you remain responsible for third-party AI systems
- **Continuous monitoring** turns compliance from project to sustainable program
- **Metrics and KPIs** demonstrate compliance and identify improvement opportunities
- **Budget realistically**: Include ongoing operational costs, not just implementation
- **Stakeholder engagement** builds the organisational support needed for success