/**
 * EU AI Act Assessment Questions
 *
 * Comprehensive assessment questions based on the EU AI Act (Regulation 2024/1689)
 * covering all major compliance areas for AI systems.
 *
 * References:
 * - Article 5: Prohibited AI practices
 * - Article 6: Classification rules for high-risk AI systems
 * - Article 9: Risk management system
 * - Article 10: Data and data governance
 * - Article 11: Technical documentation
 * - Article 12: Record-keeping
 * - Article 13: Transparency and provision of information to deployers
 * - Article 14: Human oversight
 * - Article 15: Accuracy, robustness and cybersecurity
 * - Article 50: Transparency obligations for certain AI systems
 * - Annex I: High-risk AI systems (Union harmonisation legislation)
 * - Annex III: High-risk AI systems (standalone)
 * - Annex IV: Technical documentation requirements
 */

export interface AssessmentQuestion {
  id: string
  question: string
  description?: string
  category: string
  subcategory?: string
  article: string
  weight: number
  riskTrigger?: "prohibited" | "high-risk" | "limited-risk" | "minimal"
  answerType: "yes_no" | "yes_no_partial" | "yes_no_na" | "scale" | "multiple_choice"
  options?: { value: string; label: string; score?: number }[]
  guidance?: string
  evidenceRequired?: string[]
  followUp?: string[]
}

export interface AssessmentSection {
  id: string
  title: string
  description: string
  article: string
  questions: AssessmentQuestion[]
}

// ============================================
// PROHIBITED PRACTICES ASSESSMENT (Article 5)
// ============================================

export const PROHIBITED_PRACTICES_QUESTIONS: AssessmentQuestion[] = [
  // Social Scoring (Article 5(1)(c))
  {
    id: "prohibited_1",
    question: "Does the AI system evaluate or classify natural persons based on their social behavior or personality characteristics?",
    description: "Social scoring by public authorities or on their behalf",
    category: "prohibited",
    subcategory: "social-scoring",
    article: "Article 5(1)(c)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "This includes any system that creates a 'social score' based on behavior, social status, or personality that leads to detrimental treatment.",
    evidenceRequired: ["System functionality documentation", "Use case descriptions"],
  },
  {
    id: "prohibited_2",
    question: "Could the social evaluation lead to detrimental or unfavorable treatment in contexts unrelated to the original data collection?",
    description: "Cross-context negative consequences from social scoring",
    category: "prohibited",
    subcategory: "social-scoring",
    article: "Article 5(1)(c)(i)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "For example, using data from social media behavior to deny access to public services.",
  },
  {
    id: "prohibited_3",
    question: "Is the detrimental treatment unjustified or disproportionate to the person's social behavior?",
    description: "Proportionality of consequences",
    category: "prohibited",
    subcategory: "social-scoring",
    article: "Article 5(1)(c)(ii)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
  },

  // Subliminal Manipulation (Article 5(1)(a))
  {
    id: "prohibited_4",
    question: "Does the AI system deploy subliminal techniques beyond a person's consciousness?",
    description: "Use of techniques that manipulate without awareness",
    category: "prohibited",
    subcategory: "manipulation",
    article: "Article 5(1)(a)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Subliminal techniques are those designed to operate below the threshold of conscious perception.",
  },
  {
    id: "prohibited_5",
    question: "Does the AI system use purposefully manipulative or deceptive techniques to materially distort behavior?",
    description: "Intentional manipulation causing significant behavioral change",
    category: "prohibited",
    subcategory: "manipulation",
    article: "Article 5(1)(a)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "This includes dark patterns, deceptive design, or manipulative interfaces that impair decision-making.",
  },
  {
    id: "prohibited_6",
    question: "Could this manipulation cause or be reasonably likely to cause significant harm to the person or others?",
    description: "Potential for physical, psychological, or financial harm",
    category: "prohibited",
    subcategory: "manipulation",
    article: "Article 5(1)(a)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
  },

  // Exploitation of Vulnerabilities (Article 5(1)(b))
  {
    id: "prohibited_7",
    question: "Does the AI system exploit vulnerabilities of persons due to their age (children or elderly)?",
    description: "Targeting age-related vulnerabilities",
    category: "prohibited",
    subcategory: "exploitation",
    article: "Article 5(1)(b)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Systems that take advantage of limited cognitive abilities or experience of young or elderly persons.",
  },
  {
    id: "prohibited_8",
    question: "Does the AI system exploit vulnerabilities due to disability?",
    description: "Targeting disability-related vulnerabilities",
    category: "prohibited",
    subcategory: "exploitation",
    article: "Article 5(1)(b)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
  },
  {
    id: "prohibited_9",
    question: "Does the AI system exploit specific social or economic situations to materially distort behavior?",
    description: "Targeting socioeconomic vulnerabilities",
    category: "prohibited",
    subcategory: "exploitation",
    article: "Article 5(1)(b)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "For example, predatory lending AI targeting financially distressed individuals.",
  },

  // Real-time Remote Biometric Identification (Article 5(1)(h))
  {
    id: "prohibited_10",
    question: "Is the AI system used for real-time remote biometric identification in publicly accessible spaces?",
    description: "Live biometric identification in public",
    category: "prohibited",
    subcategory: "biometric",
    article: "Article 5(1)(h)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Real-time means identification happens instantaneously or with minimal delay, in public spaces like streets, parks, or transit stations.",
  },
  {
    id: "prohibited_11",
    question: "Is this system used for law enforcement purposes?",
    description: "Law enforcement use of real-time biometric ID",
    category: "prohibited",
    subcategory: "biometric",
    article: "Article 5(1)(h)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Limited exceptions exist for specific law enforcement scenarios (Article 5(2)).",
    followUp: ["prohibited_12", "prohibited_13"],
  },
  {
    id: "prohibited_12",
    question: "If for law enforcement, is it strictly necessary for targeted search for specific victims or missing persons?",
    description: "Exception: victim/missing person search",
    category: "prohibited",
    subcategory: "biometric",
    article: "Article 5(2)(a)",
    weight: -5,
    answerType: "yes_no_na",
    guidance: "This exception may apply but requires prior judicial authorization.",
  },
  {
    id: "prohibited_13",
    question: "If for law enforcement, is it for preventing imminent threat to life or terrorist attack?",
    description: "Exception: imminent threat prevention",
    category: "prohibited",
    subcategory: "biometric",
    article: "Article 5(2)(b)(c)",
    weight: -5,
    answerType: "yes_no_na",
    guidance: "This exception requires strict necessity and prior authorization where feasible.",
  },

  // Emotion Recognition in Workplace/Education (Article 5(1)(f))
  {
    id: "prohibited_14",
    question: "Does the AI system infer emotions of natural persons in workplace settings?",
    description: "Workplace emotion recognition",
    category: "prohibited",
    subcategory: "emotion-recognition",
    article: "Article 5(1)(f)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Emotion recognition in workplace is prohibited except for medical or safety reasons.",
    followUp: ["prohibited_15"],
  },
  {
    id: "prohibited_15",
    question: "If workplace emotion recognition, is it solely for medical or safety reasons?",
    description: "Exception: medical/safety purposes",
    category: "prohibited",
    subcategory: "emotion-recognition",
    article: "Article 5(1)(f)",
    weight: -5,
    answerType: "yes_no_na",
    guidance: "Medical reasons include detecting driver fatigue. Safety reasons include monitoring for dangerous conditions.",
  },
  {
    id: "prohibited_16",
    question: "Does the AI system infer emotions of natural persons in educational institutions?",
    description: "Education emotion recognition",
    category: "prohibited",
    subcategory: "emotion-recognition",
    article: "Article 5(1)(f)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Emotion recognition in educational settings is generally prohibited.",
  },

  // Biometric Categorization (Article 5(1)(g))
  {
    id: "prohibited_17",
    question: "Does the AI system categorize natural persons based on biometric data to deduce race or ethnic origin?",
    description: "Biometric inference of protected characteristics",
    category: "prohibited",
    subcategory: "biometric-categorization",
    article: "Article 5(1)(g)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
  },
  {
    id: "prohibited_18",
    question: "Does the AI system use biometric data to infer political opinions, trade union membership, religious beliefs, or sexual orientation?",
    description: "Biometric inference of sensitive personal data",
    category: "prohibited",
    subcategory: "biometric-categorization",
    article: "Article 5(1)(g)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
  },

  // Facial Recognition Databases (Article 5(1)(e))
  {
    id: "prohibited_19",
    question: "Does the AI system create or expand facial recognition databases through untargeted scraping?",
    description: "Untargeted facial image collection",
    category: "prohibited",
    subcategory: "facial-database",
    article: "Article 5(1)(e)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "Untargeted scraping from internet or CCTV footage for facial recognition databases is prohibited.",
  },

  // Predictive Policing (Article 5(1)(d))
  {
    id: "prohibited_20",
    question: "Does the AI system make risk assessments of natural persons to predict criminal offenses based solely on profiling or personality traits?",
    description: "Individual predictive policing",
    category: "prohibited",
    subcategory: "predictive-policing",
    article: "Article 5(1)(d)",
    weight: 10,
    riskTrigger: "prohibited",
    answerType: "yes_no",
    guidance: "AI that predicts whether a specific person will commit a crime based on profiling is prohibited.",
  },
]

// ============================================
// HIGH-RISK CLASSIFICATION (Article 6, Annex I & III)
// ============================================

export const HIGH_RISK_CLASSIFICATION_QUESTIONS: AssessmentQuestion[] = [
  // Annex I - Union Harmonisation Legislation
  {
    id: "highrisk_annex1_1",
    question: "Is the AI system a safety component of a product covered by EU harmonisation legislation listed in Annex I?",
    description: "AI as safety component in regulated products",
    category: "high-risk-classification",
    subcategory: "annex-i",
    article: "Article 6(1)(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "Annex I includes machinery, toys, lifts, equipment for explosive atmospheres, radio equipment, pressure equipment, medical devices, vehicles, civil aviation, and more.",
  },
  {
    id: "highrisk_annex1_2",
    question: "Is the AI system itself a product covered by EU harmonisation legislation in Annex I?",
    description: "AI system as regulated product",
    category: "high-risk-classification",
    subcategory: "annex-i",
    article: "Article 6(1)(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_annex1_3",
    question: "Does the product require third-party conformity assessment under the applicable EU legislation?",
    description: "Third-party conformity assessment requirement",
    category: "high-risk-classification",
    subcategory: "annex-i",
    article: "Article 6(1)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Annex III Area 1: Biometrics
  {
    id: "highrisk_bio_1",
    question: "Is the AI system used for remote biometric identification (not real-time in public spaces)?",
    description: "Post or non-public biometric identification",
    category: "high-risk-classification",
    subcategory: "biometrics",
    article: "Annex III, 1(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "This includes 'post' remote biometric identification where identification occurs after recording.",
  },
  {
    id: "highrisk_bio_2",
    question: "Is the AI system used for biometric categorization to infer sensitive attributes?",
    description: "Biometric categorization systems",
    category: "high-risk-classification",
    subcategory: "biometrics",
    article: "Annex III, 1(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "Systems inferring sensitive or protected attributes based on biometric data, unless for filtering in lawful database searches.",
  },
  {
    id: "highrisk_bio_3",
    question: "Is the AI system used for emotion recognition?",
    description: "Emotion recognition systems",
    category: "high-risk-classification",
    subcategory: "biometrics",
    article: "Annex III, 1(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "Systems that identify emotional states from physiological, behavioral, or other indicators, except for medical or safety purposes.",
  },

  // Annex III Area 2: Critical Infrastructure
  {
    id: "highrisk_infra_1",
    question: "Is the AI system used as a safety component in the management of critical digital infrastructure?",
    description: "Critical digital infrastructure safety",
    category: "high-risk-classification",
    subcategory: "critical-infrastructure",
    article: "Annex III, 2(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_infra_2",
    question: "Is the AI system used as a safety component in road traffic management or supply of water, gas, heating, or electricity?",
    description: "Essential services infrastructure",
    category: "high-risk-classification",
    subcategory: "critical-infrastructure",
    article: "Annex III, 2(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Annex III Area 3: Education and Vocational Training
  {
    id: "highrisk_edu_1",
    question: "Is the AI system used to determine access or admission to educational institutions?",
    description: "Education admission decisions",
    category: "high-risk-classification",
    subcategory: "education",
    article: "Annex III, 3(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_edu_2",
    question: "Is the AI system used to evaluate learning outcomes, including determining progression?",
    description: "Learning assessment systems",
    category: "high-risk-classification",
    subcategory: "education",
    article: "Annex III, 3(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "Includes systems that assess student knowledge and capabilities to determine if they can progress.",
  },
  {
    id: "highrisk_edu_3",
    question: "Is the AI system used to assess the appropriate level of education for an individual?",
    description: "Educational level determination",
    category: "high-risk-classification",
    subcategory: "education",
    article: "Annex III, 3(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_edu_4",
    question: "Is the AI system used to monitor or detect prohibited behavior during tests?",
    description: "Exam proctoring systems",
    category: "high-risk-classification",
    subcategory: "education",
    article: "Annex III, 3(d)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "AI-based test proctoring and cheating detection systems.",
  },

  // Annex III Area 4: Employment and Worker Management
  {
    id: "highrisk_emp_1",
    question: "Is the AI system used for recruitment or selection, particularly for screening or filtering applications?",
    description: "Recruitment screening systems",
    category: "high-risk-classification",
    subcategory: "employment",
    article: "Annex III, 4(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "Includes CV screening, candidate ranking, interview analysis, and similar recruitment tools.",
  },
  {
    id: "highrisk_emp_2",
    question: "Is the AI system used to make decisions affecting terms of work relationships (promotion, termination, task allocation)?",
    description: "Employment decision systems",
    category: "high-risk-classification",
    subcategory: "employment",
    article: "Annex III, 4(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_emp_3",
    question: "Is the AI system used to monitor or evaluate performance of workers?",
    description: "Worker performance monitoring",
    category: "high-risk-classification",
    subcategory: "employment",
    article: "Annex III, 4(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Annex III Area 5: Essential Services
  {
    id: "highrisk_services_1",
    question: "Is the AI system used to evaluate creditworthiness or establish credit scores?",
    description: "Credit scoring systems",
    category: "high-risk-classification",
    subcategory: "essential-services",
    article: "Annex III, 5(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
    guidance: "Exception for fraud detection systems (see Article 6(3)).",
  },
  {
    id: "highrisk_services_2",
    question: "Is the AI system used for risk assessment and pricing in life and health insurance?",
    description: "Insurance risk assessment",
    category: "high-risk-classification",
    subcategory: "essential-services",
    article: "Annex III, 5(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_services_3",
    question: "Is the AI system used to evaluate eligibility for public assistance benefits or services?",
    description: "Public benefits eligibility",
    category: "high-risk-classification",
    subcategory: "essential-services",
    article: "Annex III, 5(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_services_4",
    question: "Is the AI system used to dispatch or prioritize emergency first response services?",
    description: "Emergency services dispatch",
    category: "high-risk-classification",
    subcategory: "essential-services",
    article: "Annex III, 5(d)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Annex III Area 6: Law Enforcement
  {
    id: "highrisk_law_1",
    question: "Is the AI system used by law enforcement for individual risk assessment (recidivism, crime risk)?",
    description: "Law enforcement risk assessment",
    category: "high-risk-classification",
    subcategory: "law-enforcement",
    article: "Annex III, 6(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_law_2",
    question: "Is the AI system used as a polygraph or similar tool to detect deception?",
    description: "Lie detection systems",
    category: "high-risk-classification",
    subcategory: "law-enforcement",
    article: "Annex III, 6(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_law_3",
    question: "Is the AI system used to evaluate reliability of evidence in criminal investigations?",
    description: "Evidence reliability assessment",
    category: "high-risk-classification",
    subcategory: "law-enforcement",
    article: "Annex III, 6(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_law_4",
    question: "Is the AI system used for profiling during criminal investigations?",
    description: "Criminal profiling systems",
    category: "high-risk-classification",
    subcategory: "law-enforcement",
    article: "Annex III, 6(d)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_law_5",
    question: "Is the AI system used for crime analytics regarding natural persons?",
    description: "Crime analytics involving individuals",
    category: "high-risk-classification",
    subcategory: "law-enforcement",
    article: "Annex III, 6(e)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Annex III Area 7: Migration, Asylum and Border Control
  {
    id: "highrisk_border_1",
    question: "Is the AI system used as polygraph or to assess risk in border control or asylum contexts?",
    description: "Border/asylum lie detection",
    category: "high-risk-classification",
    subcategory: "migration",
    article: "Annex III, 7(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_border_2",
    question: "Is the AI system used to assess migration or asylum applications?",
    description: "Immigration application assessment",
    category: "high-risk-classification",
    subcategory: "migration",
    article: "Annex III, 7(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_border_3",
    question: "Is the AI system used to assess security risks from persons entering Member State territory?",
    description: "Border security risk assessment",
    category: "high-risk-classification",
    subcategory: "migration",
    article: "Annex III, 7(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_border_4",
    question: "Is the AI system used to assist examination of visa or residence permit applications?",
    description: "Visa/permit application assistance",
    category: "high-risk-classification",
    subcategory: "migration",
    article: "Annex III, 7(d)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Annex III Area 8: Administration of Justice
  {
    id: "highrisk_justice_1",
    question: "Is the AI system used to assist judicial authorities in researching and interpreting facts and law?",
    description: "Judicial research assistance",
    category: "high-risk-classification",
    subcategory: "justice",
    article: "Annex III, 8(a)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_justice_2",
    question: "Is the AI system used to assist judicial authorities in applying the law to facts?",
    description: "Judicial decision assistance",
    category: "high-risk-classification",
    subcategory: "justice",
    article: "Annex III, 8(b)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },
  {
    id: "highrisk_justice_3",
    question: "Is the AI system used in alternative dispute resolution?",
    description: "ADR systems",
    category: "high-risk-classification",
    subcategory: "justice",
    article: "Annex III, 8(c)",
    weight: 8,
    riskTrigger: "high-risk",
    answerType: "yes_no",
  },

  // Article 6(3) Exceptions
  {
    id: "highrisk_exception_1",
    question: "Is the AI system intended to perform a narrow procedural task only?",
    description: "Narrow procedural task exception",
    category: "high-risk-classification",
    subcategory: "exceptions",
    article: "Article 6(3)(a)",
    weight: -4,
    answerType: "yes_no",
    guidance: "Systems performing limited procedural tasks may be exempt from high-risk classification.",
  },
  {
    id: "highrisk_exception_2",
    question: "Is the system intended only to improve the result of a previously completed human activity?",
    description: "Human activity improvement exception",
    category: "high-risk-classification",
    subcategory: "exceptions",
    article: "Article 6(3)(b)",
    weight: -4,
    answerType: "yes_no",
  },
  {
    id: "highrisk_exception_3",
    question: "Is the system intended only to detect decision-making patterns without replacing human assessment?",
    description: "Pattern detection exception",
    category: "high-risk-classification",
    subcategory: "exceptions",
    article: "Article 6(3)(c)",
    weight: -4,
    answerType: "yes_no",
  },
  {
    id: "highrisk_exception_4",
    question: "Does the system perform only preparatory tasks for an assessment in Annex III use cases?",
    description: "Preparatory task exception",
    category: "high-risk-classification",
    subcategory: "exceptions",
    article: "Article 6(3)(d)",
    weight: -4,
    answerType: "yes_no",
  },
]

// ============================================
// LIMITED RISK / TRANSPARENCY OBLIGATIONS (Article 50)
// ============================================

export const LIMITED_RISK_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "limited_1",
    question: "Does the AI system interact directly with natural persons (e.g., chatbot, virtual assistant)?",
    description: "Human-AI interaction systems",
    category: "limited-risk",
    subcategory: "transparency",
    article: "Article 50(1)",
    weight: 4,
    riskTrigger: "limited-risk",
    answerType: "yes_no",
    guidance: "Users must be informed they are interacting with an AI system unless obvious from context.",
  },
  {
    id: "limited_2",
    question: "Does the AI system generate synthetic audio, image, video, or text content?",
    description: "Content generation systems",
    category: "limited-risk",
    subcategory: "transparency",
    article: "Article 50(2)",
    weight: 4,
    riskTrigger: "limited-risk",
    answerType: "yes_no",
    guidance: "AI-generated content must be marked as artificially generated or manipulated.",
  },
  {
    id: "limited_3",
    question: "Does the AI system enable emotion recognition or biometric categorization?",
    description: "Emotion/biometric systems (not prohibited)",
    category: "limited-risk",
    subcategory: "transparency",
    article: "Article 50(3)",
    weight: 4,
    riskTrigger: "limited-risk",
    answerType: "yes_no",
    guidance: "Persons exposed must be informed of system operation.",
  },
  {
    id: "limited_4",
    question: "Does the AI system generate or manipulate images, audio, or video constituting deep fakes?",
    description: "Deep fake generation",
    category: "limited-risk",
    subcategory: "transparency",
    article: "Article 50(4)",
    weight: 4,
    riskTrigger: "limited-risk",
    answerType: "yes_no",
    guidance: "Deep fakes must be labeled as artificially generated or manipulated.",
  },
  {
    id: "limited_5",
    question: "Does the AI system generate text published to inform the public on matters of public interest?",
    description: "Public information text generation",
    category: "limited-risk",
    subcategory: "transparency",
    article: "Article 50(4)",
    weight: 4,
    riskTrigger: "limited-risk",
    answerType: "yes_no",
    guidance: "Unless subject to human editorial review and control, must be labeled as AI-generated.",
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - RISK MANAGEMENT (Article 9)
// ============================================

export const RISK_MANAGEMENT_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "risk_mgmt_1",
    question: "Is there an established risk management system for the AI system?",
    description: "Risk management system existence",
    category: "risk-management",
    article: "Article 9(1)",
    weight: 10,
    answerType: "yes_no_partial",
    guidance: "Must be a continuous iterative process throughout the entire lifecycle.",
    evidenceRequired: ["Risk management policy", "Risk management procedures"],
  },
  {
    id: "risk_mgmt_2",
    question: "Is the risk management system planned, implemented, documented, and maintained throughout the AI system lifecycle?",
    description: "Risk management lifecycle coverage",
    category: "risk-management",
    article: "Article 9(1)",
    weight: 8,
    answerType: "yes_no_partial",
    options: [
      { value: "yes", label: "Fully implemented", score: 100 },
      { value: "partial", label: "Partially implemented", score: 50 },
      { value: "no", label: "Not implemented", score: 0 },
    ],
  },
  {
    id: "risk_mgmt_3",
    question: "Have known and reasonably foreseeable risks to health, safety, or fundamental rights been identified and analyzed?",
    description: "Risk identification completeness",
    category: "risk-management",
    article: "Article 9(2)(a)",
    weight: 9,
    answerType: "yes_no_partial",
    evidenceRequired: ["Risk register", "Risk assessment documentation"],
  },
  {
    id: "risk_mgmt_4",
    question: "Are risks estimated and evaluated that may emerge when the AI system is used according to its intended purpose?",
    description: "Intended use risk assessment",
    category: "risk-management",
    article: "Article 9(2)(b)",
    weight: 8,
    answerType: "yes_no_partial",
  },
  {
    id: "risk_mgmt_5",
    question: "Are risks estimated and evaluated that may emerge under conditions of reasonably foreseeable misuse?",
    description: "Misuse risk assessment",
    category: "risk-management",
    article: "Article 9(2)(b)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Must consider how the system might be misused in ways that are reasonably foreseeable.",
  },
  {
    id: "risk_mgmt_6",
    question: "Have post-market monitoring data been evaluated to identify new risks?",
    description: "Post-market risk monitoring",
    category: "risk-management",
    article: "Article 9(2)(c)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Post-market monitoring reports", "Incident analysis"],
  },
  {
    id: "risk_mgmt_7",
    question: "Are appropriate and targeted risk management measures in place to address identified risks?",
    description: "Risk mitigation measures",
    category: "risk-management",
    article: "Article 9(4)",
    weight: 9,
    answerType: "yes_no_partial",
    evidenceRequired: ["Risk mitigation plans", "Control implementation evidence"],
  },
  {
    id: "risk_mgmt_8",
    question: "Do risk management measures give due consideration to effects on children when the system is likely to be used by them?",
    description: "Child protection considerations",
    category: "risk-management",
    article: "Article 9(4)",
    weight: 6,
    answerType: "yes_no_na",
    guidance: "Required when the system may be accessed or used by children.",
  },
  {
    id: "risk_mgmt_9",
    question: "Has the overall residual risk been assessed to be acceptable?",
    description: "Residual risk acceptance",
    category: "risk-management",
    article: "Article 9(5)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "After mitigation, remaining risk must be judged acceptable given intended purpose.",
  },
  {
    id: "risk_mgmt_10",
    question: "Are residual risks communicated to deployers through instructions for use?",
    description: "Residual risk communication",
    category: "risk-management",
    article: "Article 9(5)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["User documentation", "Instructions for use"],
  },
  {
    id: "risk_mgmt_11",
    question: "Is there a process for testing the AI system against risk management measures?",
    description: "Risk management testing",
    category: "risk-management",
    article: "Article 9(6)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Testing must identify most appropriate and targeted risk management measures.",
  },
  {
    id: "risk_mgmt_12",
    question: "Are testing procedures suitable for the intended purpose of the AI system?",
    description: "Testing procedure adequacy",
    category: "risk-management",
    article: "Article 9(7)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "risk_mgmt_13",
    question: "Is testing performed at appropriate points in the development process and before market placement?",
    description: "Testing timing appropriateness",
    category: "risk-management",
    article: "Article 9(7)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "risk_mgmt_14",
    question: "Is testing performed against prior defined metrics and probabilistic thresholds?",
    description: "Testing metrics and thresholds",
    category: "risk-management",
    article: "Article 9(7)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Test plans", "Performance metrics", "Threshold definitions"],
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - DATA GOVERNANCE (Article 10)
// ============================================

export const DATA_GOVERNANCE_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "data_gov_1",
    question: "Are training, validation, and testing data sets subject to appropriate data governance practices?",
    description: "Data governance framework",
    category: "data-governance",
    article: "Article 10(2)",
    weight: 10,
    answerType: "yes_no_partial",
    evidenceRequired: ["Data governance policy", "Data management procedures"],
  },
  {
    id: "data_gov_2",
    question: "Are relevant design choices documented for data sets?",
    description: "Design choice documentation",
    category: "data-governance",
    article: "Article 10(2)(a)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "data_gov_3",
    question: "Are data collection processes documented?",
    description: "Data collection documentation",
    category: "data-governance",
    article: "Article 10(2)(b)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Data collection procedures", "Source documentation"],
  },
  {
    id: "data_gov_4",
    question: "Are data preparation operations (annotation, labeling, cleaning, enrichment) documented?",
    description: "Data preparation documentation",
    category: "data-governance",
    article: "Article 10(2)(b)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Data preparation procedures", "Annotation guidelines"],
  },
  {
    id: "data_gov_5",
    question: "Are the assumptions the data are meant to measure and represent clearly formulated?",
    description: "Data assumption documentation",
    category: "data-governance",
    article: "Article 10(2)(c)",
    weight: 6,
    answerType: "yes_no_partial",
  },
  {
    id: "data_gov_6",
    question: "Is there an assessment of data availability, quantity, and suitability?",
    description: "Data quality assessment",
    category: "data-governance",
    article: "Article 10(2)(d)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Data quality reports", "Gap analysis"],
  },
  {
    id: "data_gov_7",
    question: "Are possible biases in the data examined?",
    description: "Bias examination",
    category: "data-governance",
    article: "Article 10(2)(f)",
    weight: 9,
    answerType: "yes_no_partial",
    guidance: "Must examine biases that may affect health, safety, and fundamental rights.",
    evidenceRequired: ["Bias analysis reports", "Fairness assessments"],
  },
  {
    id: "data_gov_8",
    question: "Are possible data gaps or shortcomings identified and addressed?",
    description: "Data gap identification",
    category: "data-governance",
    article: "Article 10(2)(g)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "data_gov_9",
    question: "Are training, validation, and testing data sets relevant, sufficiently representative, and free of errors?",
    description: "Data quality requirements",
    category: "data-governance",
    article: "Article 10(3)",
    weight: 9,
    answerType: "yes_no_partial",
    guidance: "Must be to the best extent possible in view of intended purpose.",
  },
  {
    id: "data_gov_10",
    question: "Do data sets have appropriate statistical properties for the intended purpose?",
    description: "Statistical property adequacy",
    category: "data-governance",
    article: "Article 10(3)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "data_gov_11",
    question: "Do data sets take into account characteristics specific to geographic, contextual, behavioral, or functional settings?",
    description: "Contextual data appropriateness",
    category: "data-governance",
    article: "Article 10(4)",
    weight: 7,
    answerType: "yes_no_partial",
    guidance: "Data should reflect the specific context where the system will be used.",
  },
  {
    id: "data_gov_12",
    question: "Are special categories of personal data processed only where strictly necessary for bias monitoring/correction?",
    description: "Special category data processing",
    category: "data-governance",
    article: "Article 10(5)",
    weight: 8,
    answerType: "yes_no_na",
    guidance: "Processing sensitive data for bias detection requires strict necessity and appropriate safeguards.",
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - TECHNICAL DOCUMENTATION (Article 11)
// ============================================

export const TECHNICAL_DOCUMENTATION_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "tech_doc_1",
    question: "Is technical documentation drawn up before the AI system is placed on the market or put into service?",
    description: "Documentation timing",
    category: "technical-documentation",
    article: "Article 11(1)",
    weight: 9,
    answerType: "yes_no",
    evidenceRequired: ["Technical documentation package"],
  },
  {
    id: "tech_doc_2",
    question: "Is the technical documentation kept up to date throughout the system lifecycle?",
    description: "Documentation maintenance",
    category: "technical-documentation",
    article: "Article 11(1)",
    weight: 8,
    answerType: "yes_no_partial",
  },
  {
    id: "tech_doc_3",
    question: "Does documentation contain a general description of the AI system and its intended purpose?",
    description: "System description completeness",
    category: "technical-documentation",
    article: "Annex IV, 1",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["System overview document"],
  },
  {
    id: "tech_doc_4",
    question: "Is information about elements of the AI system and development process documented?",
    description: "Development process documentation",
    category: "technical-documentation",
    article: "Annex IV, 2",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Architecture documentation", "Development methodology"],
  },
  {
    id: "tech_doc_5",
    question: "Is detailed information about monitoring, functioning, and control documented?",
    description: "Operational documentation",
    category: "technical-documentation",
    article: "Annex IV, 3",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "tech_doc_6",
    question: "Is the risk management system fully described?",
    description: "Risk management documentation",
    category: "technical-documentation",
    article: "Annex IV, 4",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Risk management documentation"],
  },
  {
    id: "tech_doc_7",
    question: "Are changes made during the AI system lifecycle documented?",
    description: "Change documentation",
    category: "technical-documentation",
    article: "Annex IV, 5",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Change log", "Version control records"],
  },
  {
    id: "tech_doc_8",
    question: "Are harmonised standards or common specifications applied documented?",
    description: "Standards compliance documentation",
    category: "technical-documentation",
    article: "Annex IV, 6",
    weight: 6,
    answerType: "yes_no_partial",
  },
  {
    id: "tech_doc_9",
    question: "Is the EU declaration of conformity available?",
    description: "Declaration of conformity",
    category: "technical-documentation",
    article: "Annex IV, 7",
    weight: 8,
    answerType: "yes_no",
    evidenceRequired: ["EU Declaration of Conformity"],
  },
  {
    id: "tech_doc_10",
    question: "Is a description of the post-market monitoring system included?",
    description: "Post-market monitoring documentation",
    category: "technical-documentation",
    article: "Annex IV, 8",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Post-market monitoring plan"],
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - RECORD-KEEPING (Article 12)
// ============================================

export const RECORD_KEEPING_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "record_1",
    question: "Are logs automatically generated by the AI system?",
    description: "Automatic logging capability",
    category: "record-keeping",
    article: "Article 12(1)",
    weight: 9,
    answerType: "yes_no",
    guidance: "High-risk AI systems must have automatic logging capabilities.",
    evidenceRequired: ["Logging system documentation", "Log samples"],
  },
  {
    id: "record_2",
    question: "Do logs allow traceability of the AI system's functioning throughout its lifecycle?",
    description: "Lifecycle traceability",
    category: "record-keeping",
    article: "Article 12(1)",
    weight: 8,
    answerType: "yes_no_partial",
  },
  {
    id: "record_3",
    question: "Are logs appropriate to the intended purpose of the AI system?",
    description: "Log appropriateness",
    category: "record-keeping",
    article: "Article 12(1)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "record_4",
    question: "Do logs comply with recognized standards or common specifications?",
    description: "Log standard compliance",
    category: "record-keeping",
    article: "Article 12(1)",
    weight: 6,
    answerType: "yes_no_partial",
  },
  {
    id: "record_5",
    question: "Do logging capabilities enable recording of events relevant to identifying situations requiring intervention?",
    description: "Intervention trigger logging",
    category: "record-keeping",
    article: "Article 12(2)(a)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Must log events that may require human intervention or system shutdown.",
  },
  {
    id: "record_6",
    question: "Do logs facilitate post-market monitoring?",
    description: "Post-market monitoring support",
    category: "record-keeping",
    article: "Article 12(2)(b)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "record_7",
    question: "Do logs enable reconstruction and evaluation of AI system behavior?",
    description: "Behavior reconstruction capability",
    category: "record-keeping",
    article: "Article 12(2)(c)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Critical for incident investigation and audit purposes.",
  },
  {
    id: "record_8",
    question: "Are logs retained for an appropriate period based on intended purpose and legal obligations?",
    description: "Log retention policy",
    category: "record-keeping",
    article: "Article 12(3)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Data retention policy", "Log retention configuration"],
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - TRANSPARENCY (Article 13)
// ============================================

export const TRANSPARENCY_REQUIREMENTS_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "trans_1",
    question: "Is the AI system designed to ensure its operation is sufficiently transparent?",
    description: "Transparency by design",
    category: "transparency",
    article: "Article 13(1)",
    weight: 9,
    answerType: "yes_no_partial",
    guidance: "Deployers must be able to interpret system output and use it appropriately.",
  },
  {
    id: "trans_2",
    question: "Are clear instructions for use provided to deployers?",
    description: "Instructions for use",
    category: "transparency",
    article: "Article 13(2)",
    weight: 8,
    answerType: "yes_no",
    evidenceRequired: ["User manual", "Instructions for use document"],
  },
  {
    id: "trans_3",
    question: "Do instructions include information about provider identity and contact details?",
    description: "Provider identification",
    category: "transparency",
    article: "Article 13(3)(a)",
    weight: 6,
    answerType: "yes_no",
  },
  {
    id: "trans_4",
    question: "Do instructions include characteristics, capabilities, and limitations of AI system performance?",
    description: "Performance characteristics",
    category: "transparency",
    article: "Article 13(3)(b)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Must include accuracy levels, robustness, cybersecurity, and circumstances where risks may emerge.",
  },
  {
    id: "trans_5",
    question: "Are any changes to the AI system pre-determined by the provider documented?",
    description: "Pre-determined change documentation",
    category: "transparency",
    article: "Article 13(3)(c)",
    weight: 6,
    answerType: "yes_no_na",
  },
  {
    id: "trans_6",
    question: "Are human oversight measures including technical measures clearly documented?",
    description: "Human oversight documentation",
    category: "transparency",
    article: "Article 13(3)(d)",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Human oversight procedures"],
  },
  {
    id: "trans_7",
    question: "Are computational and hardware resources needed for operation specified?",
    description: "Resource requirements",
    category: "transparency",
    article: "Article 13(3)(e)",
    weight: 5,
    answerType: "yes_no",
  },
  {
    id: "trans_8",
    question: "Is the expected lifetime and maintenance measures documented?",
    description: "Lifetime and maintenance",
    category: "transparency",
    article: "Article 13(3)(f)",
    weight: 5,
    answerType: "yes_no",
  },
  {
    id: "trans_9",
    question: "Are input data specifications and requirements documented?",
    description: "Input data specifications",
    category: "transparency",
    article: "Article 13(3)(b)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "trans_10",
    question: "Are deployers informed of specific risks to groups likely to be affected?",
    description: "Affected group risk disclosure",
    category: "transparency",
    article: "Article 13(3)(b)(i)",
    weight: 8,
    answerType: "yes_no_partial",
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - HUMAN OVERSIGHT (Article 14)
// ============================================

export const HUMAN_OVERSIGHT_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "oversight_1",
    question: "Is the AI system designed to be effectively overseen by natural persons?",
    description: "Human oversight design",
    category: "human-oversight",
    article: "Article 14(1)",
    weight: 10,
    answerType: "yes_no_partial",
    guidance: "Must be designed to allow human oversight during use.",
  },
  {
    id: "oversight_2",
    question: "Are appropriate human-machine interface tools provided to enable oversight?",
    description: "Interface tools for oversight",
    category: "human-oversight",
    article: "Article 14(1)",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Interface documentation", "Oversight tool specifications"],
  },
  {
    id: "oversight_3",
    question: "Does oversight aim to prevent or minimize risks to health, safety, or fundamental rights?",
    description: "Oversight risk prevention purpose",
    category: "human-oversight",
    article: "Article 14(2)",
    weight: 9,
    answerType: "yes_no_partial",
  },
  {
    id: "oversight_4",
    question: "Are human overseers enabled to fully understand the AI system's capabilities and limitations?",
    description: "Capability understanding",
    category: "human-oversight",
    article: "Article 14(4)(a)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Overseers must be able to properly monitor operation.",
  },
  {
    id: "oversight_5",
    question: "Can human overseers properly detect and address automation bias?",
    description: "Automation bias awareness",
    category: "human-oversight",
    article: "Article 14(4)(b)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Especially relevant where decisions affect natural persons.",
  },
  {
    id: "oversight_6",
    question: "Can human overseers correctly interpret the AI system's output?",
    description: "Output interpretability",
    category: "human-oversight",
    article: "Article 14(4)(c)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Taking into account relevant tools and methods for interpretation.",
  },
  {
    id: "oversight_7",
    question: "Can human overseers decide not to use the AI system in any particular situation?",
    description: "Decision to not use system",
    category: "human-oversight",
    article: "Article 14(4)(d)",
    weight: 7,
    answerType: "yes_no",
  },
  {
    id: "oversight_8",
    question: "Can human overseers disregard, override, or reverse the AI system's output?",
    description: "Override capability",
    category: "human-oversight",
    article: "Article 14(4)(d)",
    weight: 9,
    answerType: "yes_no",
    guidance: "Critical for maintaining human control over AI decisions.",
  },
  {
    id: "oversight_9",
    question: "Can human overseers interrupt or stop the AI system operation?",
    description: "System interruption capability",
    category: "human-oversight",
    article: "Article 14(4)(e)",
    weight: 9,
    answerType: "yes_no",
    guidance: "Must be able to stop system using a 'stop' button or similar procedure.",
  },
  {
    id: "oversight_10",
    question: "Are human overseers adequately trained to perform their oversight duties?",
    description: "Overseer training",
    category: "human-oversight",
    article: "Article 14(2)",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Training materials", "Competency records"],
  },
  {
    id: "oversight_11",
    question: "Is the level of human oversight commensurate with the risks and context of use?",
    description: "Proportionate oversight",
    category: "human-oversight",
    article: "Article 14(2)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "Higher risks require more intensive oversight measures.",
  },
]

// ============================================
// HIGH-RISK REQUIREMENTS - ACCURACY, ROBUSTNESS, CYBERSECURITY (Article 15)
// ============================================

export const ACCURACY_ROBUSTNESS_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "accuracy_1",
    question: "Is the AI system designed to achieve an appropriate level of accuracy?",
    description: "Accuracy by design",
    category: "accuracy-robustness",
    article: "Article 15(1)",
    weight: 9,
    answerType: "yes_no_partial",
    guidance: "Accuracy must be appropriate for the intended purpose.",
  },
  {
    id: "accuracy_2",
    question: "Are accuracy levels declared in instructions for use?",
    description: "Accuracy declaration",
    category: "accuracy-robustness",
    article: "Article 15(1)",
    weight: 8,
    answerType: "yes_no",
    evidenceRequired: ["Accuracy metrics", "Performance test results"],
  },
  {
    id: "accuracy_3",
    question: "Is the AI system resilient to errors, faults, or inconsistencies in input data?",
    description: "Input resilience",
    category: "accuracy-robustness",
    article: "Article 15(2)",
    weight: 8,
    answerType: "yes_no_partial",
    guidance: "System should handle imperfect inputs appropriately.",
  },
  {
    id: "accuracy_4",
    question: "Is the AI system resilient to errors or inconsistencies arising from system/environment interaction?",
    description: "Environment interaction resilience",
    category: "accuracy-robustness",
    article: "Article 15(2)",
    weight: 7,
    answerType: "yes_no_partial",
    guidance: "Including interactions with other AI systems.",
  },
  {
    id: "accuracy_5",
    question: "Are technical redundancy solutions implemented including backup or fail-safe mechanisms?",
    description: "Redundancy mechanisms",
    category: "accuracy-robustness",
    article: "Article 15(2)",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Redundancy design documentation", "Failover procedures"],
  },
  {
    id: "accuracy_6",
    question: "Is the AI system resilient against unauthorized attempts to alter its use, outputs, or performance?",
    description: "Adversarial robustness",
    category: "accuracy-robustness",
    article: "Article 15(3)",
    weight: 9,
    answerType: "yes_no_partial",
    guidance: "Must be protected against adversarial attacks.",
  },
  {
    id: "accuracy_7",
    question: "Is the system resilient against attempts to exploit system vulnerabilities by third parties?",
    description: "Vulnerability exploitation protection",
    category: "accuracy-robustness",
    article: "Article 15(3)",
    weight: 9,
    answerType: "yes_no_partial",
  },
  {
    id: "accuracy_8",
    question: "Are technical solutions in place to address AI-specific vulnerabilities (data poisoning, adversarial examples, model inversion)?",
    description: "AI-specific security",
    category: "accuracy-robustness",
    article: "Article 15(4)",
    weight: 9,
    answerType: "yes_no_partial",
    evidenceRequired: ["Security assessment", "Vulnerability testing results"],
  },
  {
    id: "accuracy_9",
    question: "Are appropriate cybersecurity measures implemented to protect against attacks?",
    description: "Cybersecurity measures",
    category: "accuracy-robustness",
    article: "Article 15(5)",
    weight: 9,
    answerType: "yes_no_partial",
    evidenceRequired: ["Security policy", "Penetration testing results"],
  },
  {
    id: "accuracy_10",
    question: "Are regular security assessments performed on the AI system?",
    description: "Security assessment frequency",
    category: "accuracy-robustness",
    article: "Article 15(5)",
    weight: 7,
    answerType: "yes_no_partial",
    evidenceRequired: ["Security audit reports"],
  },
]

// ============================================
// CONFORMITY ASSESSMENT (Article 43)
// ============================================

export const CONFORMITY_ASSESSMENT_QUESTIONS: AssessmentQuestion[] = [
  {
    id: "conform_1",
    question: "Has a conformity assessment procedure been completed before placing the system on market or putting it into service?",
    description: "Conformity assessment completion",
    category: "conformity-assessment",
    article: "Article 43(1)",
    weight: 10,
    answerType: "yes_no",
    evidenceRequired: ["Conformity assessment report", "EU Declaration of Conformity"],
  },
  {
    id: "conform_2",
    question: "If the system is covered by Annex I legislation, has conformity been demonstrated under that legislation?",
    description: "Harmonised legislation conformity",
    category: "conformity-assessment",
    article: "Article 43(2)",
    weight: 8,
    answerType: "yes_no_na",
  },
  {
    id: "conform_3",
    question: "For Annex III high-risk systems, has internal control procedure (Annex VI) been followed?",
    description: "Internal control completion",
    category: "conformity-assessment",
    article: "Article 43(3)",
    weight: 9,
    answerType: "yes_no_na",
    guidance: "Most high-risk AI systems use internal control for conformity assessment.",
  },
  {
    id: "conform_4",
    question: "For biometric systems under Annex III point 1, has third-party conformity assessment been performed?",
    description: "Biometric system third-party assessment",
    category: "conformity-assessment",
    article: "Article 43(4)",
    weight: 9,
    answerType: "yes_no_na",
    guidance: "Biometric identification and categorization systems require notified body involvement.",
  },
  {
    id: "conform_5",
    question: "Has a quality management system been established, implemented, and maintained?",
    description: "Quality management system",
    category: "conformity-assessment",
    article: "Article 17",
    weight: 9,
    answerType: "yes_no_partial",
    evidenceRequired: ["QMS documentation", "QMS procedures"],
  },
  {
    id: "conform_6",
    question: "Does the quality management system ensure AI system compliance with the Regulation?",
    description: "QMS compliance scope",
    category: "conformity-assessment",
    article: "Article 17(1)",
    weight: 8,
    answerType: "yes_no_partial",
  },
  {
    id: "conform_7",
    question: "Is there a documented strategy for regulatory compliance?",
    description: "Compliance strategy documentation",
    category: "conformity-assessment",
    article: "Article 17(1)(a)",
    weight: 7,
    answerType: "yes_no",
    evidenceRequired: ["Compliance strategy document"],
  },
  {
    id: "conform_8",
    question: "Are procedures for design, design control, and design verification documented?",
    description: "Design procedures",
    category: "conformity-assessment",
    article: "Article 17(1)(b)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "conform_9",
    question: "Are procedures for development, quality control, and quality assurance documented?",
    description: "Development and quality procedures",
    category: "conformity-assessment",
    article: "Article 17(1)(c)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "conform_10",
    question: "Is there a procedure for examination, testing, and validation before, during, and after development?",
    description: "Testing procedures",
    category: "conformity-assessment",
    article: "Article 17(1)(d)",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Test procedures", "Validation protocols"],
  },
  {
    id: "conform_11",
    question: "Are technical specifications applied documented (standards, common specifications)?",
    description: "Technical specifications",
    category: "conformity-assessment",
    article: "Article 17(1)(e)",
    weight: 6,
    answerType: "yes_no_partial",
  },
  {
    id: "conform_12",
    question: "Is there a post-market monitoring system implemented?",
    description: "Post-market monitoring",
    category: "conformity-assessment",
    article: "Article 17(1)(h)",
    weight: 8,
    answerType: "yes_no_partial",
    evidenceRequired: ["Post-market monitoring plan"],
  },
  {
    id: "conform_13",
    question: "Are procedures for serious incident and malfunctioning reporting in place?",
    description: "Incident reporting procedures",
    category: "conformity-assessment",
    article: "Article 17(1)(i)",
    weight: 8,
    answerType: "yes_no",
    evidenceRequired: ["Incident reporting procedure"],
  },
  {
    id: "conform_14",
    question: "Are corrective action procedures documented and implemented?",
    description: "Corrective action procedures",
    category: "conformity-assessment",
    article: "Article 17(1)(k)",
    weight: 7,
    answerType: "yes_no_partial",
  },
  {
    id: "conform_15",
    question: "Is there a system for communication with competent authorities?",
    description: "Authority communication system",
    category: "conformity-assessment",
    article: "Article 17(1)(j)",
    weight: 6,
    answerType: "yes_no",
  },
]

// ============================================
// ASSESSMENT SECTIONS GROUPING
// ============================================

export const ASSESSMENT_SECTIONS: AssessmentSection[] = [
  {
    id: "prohibited-practices",
    title: "Prohibited AI Practices",
    description: "Assessment of whether the AI system falls under prohibited practices defined in Article 5",
    article: "Article 5",
    questions: PROHIBITED_PRACTICES_QUESTIONS,
  },
  {
    id: "high-risk-classification",
    title: "High-Risk Classification",
    description: "Determination of whether the AI system is classified as high-risk under Article 6 and Annex III",
    article: "Article 6, Annex I, Annex III",
    questions: HIGH_RISK_CLASSIFICATION_QUESTIONS,
  },
  {
    id: "limited-risk-transparency",
    title: "Limited Risk & Transparency Obligations",
    description: "Assessment of transparency obligations under Article 50",
    article: "Article 50",
    questions: LIMITED_RISK_QUESTIONS,
  },
  {
    id: "risk-management",
    title: "Risk Management System",
    description: "Evaluation of risk management practices as required by Article 9",
    article: "Article 9",
    questions: RISK_MANAGEMENT_QUESTIONS,
  },
  {
    id: "data-governance",
    title: "Data and Data Governance",
    description: "Assessment of data governance practices under Article 10",
    article: "Article 10",
    questions: DATA_GOVERNANCE_QUESTIONS,
  },
  {
    id: "technical-documentation",
    title: "Technical Documentation",
    description: "Review of technical documentation requirements under Article 11 and Annex IV",
    article: "Article 11, Annex IV",
    questions: TECHNICAL_DOCUMENTATION_QUESTIONS,
  },
  {
    id: "record-keeping",
    title: "Record-Keeping and Logging",
    description: "Assessment of automatic logging capabilities under Article 12",
    article: "Article 12",
    questions: RECORD_KEEPING_QUESTIONS,
  },
  {
    id: "transparency",
    title: "Transparency and Information to Deployers",
    description: "Evaluation of transparency requirements under Article 13",
    article: "Article 13",
    questions: TRANSPARENCY_REQUIREMENTS_QUESTIONS,
  },
  {
    id: "human-oversight",
    title: "Human Oversight",
    description: "Assessment of human oversight mechanisms under Article 14",
    article: "Article 14",
    questions: HUMAN_OVERSIGHT_QUESTIONS,
  },
  {
    id: "accuracy-robustness",
    title: "Accuracy, Robustness and Cybersecurity",
    description: "Evaluation of accuracy, resilience and security requirements under Article 15",
    article: "Article 15",
    questions: ACCURACY_ROBUSTNESS_QUESTIONS,
  },
  {
    id: "conformity-assessment",
    title: "Conformity Assessment",
    description: "Assessment of conformity assessment and quality management requirements",
    article: "Article 43, Article 17",
    questions: CONFORMITY_ASSESSMENT_QUESTIONS,
  },
]

// ============================================
// HELPER FUNCTIONS
// ============================================

export function getAllQuestions(): AssessmentQuestion[] {
  return ASSESSMENT_SECTIONS.flatMap(section => section.questions)
}

export function getQuestionsByCategory(category: string): AssessmentQuestion[] {
  return getAllQuestions().filter(q => q.category === category)
}

export function getSectionById(sectionId: string): AssessmentSection | undefined {
  return ASSESSMENT_SECTIONS.find(s => s.id === sectionId)
}

export function getQuestionById(questionId: string): AssessmentQuestion | undefined {
  return getAllQuestions().find(q => q.id === questionId)
}

// Re-export calculation functions from utils for backward compatibility
// These functions have been moved to @/lib/utils/risk-classification and @/lib/utils/compliance-scoring
export { calculateRiskClassification } from "@/lib/utils/risk-classification"
export { calculateComplianceScore } from "@/lib/utils/compliance-scoring"
