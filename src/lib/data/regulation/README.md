# AI Act Compliance Training - Extracted Sections

## Expert GRC Analysis & Section Organization

This collection represents a comprehensive breakdown of **EU Regulation 2024/1689** (the AI Act) into pedagogically optimized sections for training course development.

---

## Analysis Summary

### Document Structure
- **Source:** EU AI Act (Regulation 2024/1689)
- **Total Size:** 648 KB, 7,768 lines
- **Sections Extracted:** 30 files (28 content sections + 2 navigation files)
- **Total Extracted:** 720 KB, 8,344 lines
- **Extraction Method:** Line-range extraction with expert annotation

### Files in This Directory

#### Navigation & Reference (2 files)
- **00_TABLE_OF_CONTENTS.md** - Comprehensive navigation guide with training recommendations
- **EXTRACTION_SUMMARY.md** - Technical extraction details

#### Content Sections (28 files)
- **1 Title/Introduction** - Legal foundation
- **1 Preamble** - 180+ whereas clauses (largest single section at 223 KB)
- **13 Chapters** - Complete regulatory framework
- **13 Annexes** - Technical requirements and lists

---

## Training Course Architecture

### Priority Structure for Compliance Officers

#### üî¥ **WEEK 1 - Critical Foundations**
1. **Scope & Applicability** ‚Üí `02_chapter_01_general_provisions.md`
   - Determine if your organization is in scope
   - Understand key definitions (AI system, provider, deployer)

2. **Absolute Prohibitions** ‚Üí `03_chapter_02_prohibited_ai_practices.md`
   - Know the RED LINES (social scoring, manipulation, unauthorized biometric)
   - Penalties: Up to ‚Ç¨35M or 7% global revenue

3. **Risk Classification** ‚Üí `17_annex_03_high_risk_systems.md`
   - Check if your AI falls into 8 high-risk categories
   - Employment, education, law enforcement, critical infrastructure, etc.

4. **Penalty Framework** ‚Üí `13_chapter_12_penalties.md`
   - Understand financial exposure
   - Enforcement mechanisms

#### üü° **WEEK 2-3 - High-Risk Deep Dive**
5. **High-Risk Requirements** ‚Üí `04_chapter_03_high_risk_ai_systems.md` (107 KB!)
   - Risk management systems
   - Data governance and quality requirements
   - Technical documentation (link to Annex IV)
   - Human oversight mandates
   - Accuracy, robustness, cybersecurity

6. **Transparency Obligations** ‚Üí `05_chapter_04_transparency_obligations.md`
   - User disclosure requirements
   - Deepfake labeling
   - Emotion recognition notifications

7. **Post-Market Monitoring** ‚Üí `10_chapter_09_post_market_monitoring.md`
   - Ongoing compliance obligations
   - Incident reporting
   - Market surveillance procedures

8. **Implementation Timeline** ‚Üí `14_chapter_13_final_provisions.md`
   - Key dates: Feb 2025 (prohibitions), Aug 2025 (GPAI), Aug 2027 (high-risk)

#### üü¢ **MONTH 2+ - Specialized Areas**

**If Using Foundation Models (GPT, Claude, etc.):**
- `06_chapter_05_general_purpose_ai_models.md`
- `25_annex_11_gpai_technical_documentation.md`
- `27_annex_13_systemic_risk_criteria.md` (10^25 FLOPs threshold)

**For Innovation Teams:**
- `07_chapter_06_innovation_support.md` (regulatory sandboxes)
- `11_chapter_10_codes_of_conduct.md` (voluntary standards)

**For Governance/Legal:**
- `08_chapter_07_governance.md` (European AI Board, national authorities)
- `01_preamble.md` (legislative intent for interpretation)

---

## Key Insights from GRC Expert Analysis

### 1. Risk-Based Approach
The regulation uses a **four-tier pyramid**:
- **Unacceptable Risk** ‚Üí Prohibited (Chapter II)
- **High Risk** ‚Üí Strict requirements (Chapter III + Annexes)
- **Limited Risk** ‚Üí Transparency obligations (Chapter IV)
- **Minimal Risk** ‚Üí Voluntary codes (Chapter X)

### 2. Most Critical Annexes

**Annex III (High-Risk Systems)** - Your classification checklist:
1. Biometrics (if legally permitted)
2. Critical infrastructure
3. Education & vocational training
4. Employment & worker management
5. Essential services (healthcare, credit scoring, insurance)
6. Law enforcement (if legally permitted)
7. Migration, asylum, border control
8. Justice & democratic processes

**Annex IV (Technical Documentation)** - What you must maintain:
- General system description and intended purpose
- Development, training, testing methodology
- Data governance and datasets used
- Human oversight measures
- Accuracy, robustness, cybersecurity measures
- Risk management system

### 3. Governance Structure

**European Level:**
- European AI Board (Article 64+)
- European Artificial Intelligence Office (coordination)

**National Level:**
- Market surveillance authorities
- Notifying authorities
- Notified bodies (conformity assessment)

### 4. Timeline Reality Check

| Date | What Happens | Impact |
|------|-------------|--------|
| **2 Feb 2025** | Prohibited practices ban | Immediate compliance required |
| **2 Aug 2025** | GPAI obligations active | Foundation model providers must comply |
| **2 Aug 2026** | High-risk for new systems | New high-risk AI must be compliant |
| **2 Aug 2027** | Full application | All high-risk AI must be compliant |

### 5. Financial Exposure

**Tier 1 Violations (Prohibited Practices):**
- ‚Ç¨35 million OR 7% of global annual turnover (whichever is higher)

**Tier 2 Violations (High-Risk Non-Compliance):**
- ‚Ç¨15 million OR 3% of global annual turnover

**Tier 3 Violations (Information Obligations):**
- ‚Ç¨7.5 million OR 1.5% of global annual turnover

---

## How to Use These Sections

### For Training Course Development:
1. **Start with 00_TABLE_OF_CONTENTS.md** - Contains full course structure recommendations
2. **Each section has training notes** - Expert commentary on compliance relevance
3. **Cross-references included** - Links between chapters and annexes
4. **Modular design** - Mix and match sections based on audience

### Suggested Course Modules:

**Module 1: AI Act Fundamentals (2-3 hours)**
- Target: All staff
- Files: 00, 01 (excerpt), 02, 03

**Module 2: High-Risk System Compliance (4-5 hours)**
- Target: Product managers, engineers, compliance officers
- Files: 04, 17, 18, 22

**Module 3: GPAI Compliance (2-3 hours)**
- Target: Foundation model developers/users
- Files: 06, 25, 26, 27

**Module 4: Governance & Penalties (2 hours)**
- Target: C-suite, legal, GRC
- Files: 08, 13, 14

**Module 5: Innovation Pathways (2 hours)**
- Target: R&D, innovation teams
- Files: 07, 11

---

## Quality Assurance

All sections have been:
- ‚úÖ Verified for completeness
- ‚úÖ Annotated with training notes
- ‚úÖ Cross-referenced to related sections
- ‚úÖ Formatted in markdown for easy viewing
- ‚úÖ Organized by priority and topic

### Verification Results:
- **30 files created** (28 content + 2 navigation)
- **All chapters extracted** (I-XIII)
- **All annexes extracted** (I-XIII)
- **Total lines:** 8,344 (from 7,768 original)
- **Size check:** 720 KB extracted from 648 KB source

---

## Quick Reference

### Find by Topic:
- **Definitions** ‚Üí 02_chapter_01
- **Prohibitions** ‚Üí 03_chapter_02
- **High-risk list** ‚Üí 17_annex_03
- **Documentation** ‚Üí 18_annex_04
- **GPAI models** ‚Üí 06_chapter_05
- **Penalties** ‚Üí 13_chapter_12
- **Timelines** ‚Üí 14_chapter_13

### Find by Stakeholder:
- **Providers** ‚Üí Chapters 1, 2, 3, 4, 5
- **Deployers** ‚Üí Chapters 1, 2, 3, 4
- **Distributors** ‚Üí Chapter 3 (Section 3)
- **Importers** ‚Üí Chapter 3 (Section 3)
- **Regulators** ‚Üí Chapters 7, 9

---

## Expert Recommendations

### For Course Development:
1. **Start broad, go deep** - Foundation ‚Üí Specific obligations
2. **Use case studies** - Each prohibition and high-risk category deserves real examples
3. **Interactive elements** - Risk assessment exercises using Annex III
4. **Practical tools** - Documentation templates based on Annex IV
5. **Regular updates** - Monitor delegated acts and implementing regulations

### Common Pitfalls to Address:
1. ‚ùå "We're not in the EU" ‚Üí Territorial scope includes non-EU providers if output used in EU
2. ‚ùå "We're just using AI, not providing" ‚Üí Deployers have significant obligations too
3. ‚ùå "Our AI isn't high-risk" ‚Üí Check Annex III carefully, many surprised
4. ‚ùå "We have time" ‚Üí Prohibited practices enforceable Feb 2025
5. ‚ùå "It's just about compliance" ‚Üí Strategic opportunity for trustworthy AI leadership

---

## Next Steps

1. **Gap Analysis** - Map current AI systems to risk categories
2. **Compliance Roadmap** - Prioritize based on timelines and risk
3. **Documentation System** - Establish technical documentation processes
4. **Training Rollout** - Use these sections to build role-based training
5. **Ongoing Monitoring** - Track delegated acts and guidance documents

---

## About This Analysis

**Analyzed by:** AI compliance expert (GRC specialist with AI expertise)
**Analysis Level:** Deep structural and pedagogical review
**Intended Use:** Training course development for AI Act compliance
**Last Updated:** October 2025
**Regulation Version:** EU 2024/1689 (Official Journal L series, 12 July 2024)

---

**Questions? Start with:** `00_TABLE_OF_CONTENTS.md` for navigation and course structure recommendations.

**Ready to dive in?** Follow the priority reading order above, or jump to sections relevant to your organization's AI use cases.
